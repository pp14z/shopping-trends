# Shopping Trends - ETL, API REST y Dashboard de An√°lisis

## üìå Descripci√≥n general

Soluci√≥n end-to-end para el an√°lisis de tendencias de compra. El sistema extrae datos de transacciones (3,900+ registros), los transforma con Python/Pandas, los almacena en PostgreSQL y los expone a trav√©s de una API REST para su visualizaci√≥n en un dashboard interactivo.

**Tecnolog√≠as**:
- **ETL**: Pandas, Celery
- **Backend**: Django REST Framework (DRF), PostgreSQL
- **Frontend**: Next.js, TypeScript, Shadcn/ui
- **Infraestructura**: Docker-compose

---

## üöÄ Funcionalidades Clave

### ETL
- Ingesta de datos simulando una carga desde S3 (archivo CSV local).
- Limpieza y transformaci√≥n de datos con Pandas.
- Normalizaci√≥n del dataset en un modelo relacional (clientes, productos, transacciones).
- Carga optimizada a PostgreSQL utilizando inserciones masivas (`bulk_create`).
- Estructura preparada para ejecuci√≥n peri√≥dica con Celery (actualizaciones autom√°ticas).

### API REST
- Endpoints organizados por recurso: clientes, productos, ventas.
- Soporte para filtros y b√∫squedas por par√°metros clave.
- Documentaci√≥n generada autom√°ticamente con Swagger / OpenAPI.
- Validaci√≥n de datos y manejo de errores consistente.

### Dashboard Interactivo
- Visualizaci√≥n de KPIs: ventas totales, productos m√°s vendidos, ingresos promedio por categor√≠a.
- Gr√°ficos din√°micos integrados con Chart.js o Recharts.
- Filtros interactivos por categor√≠a, temporada y m√©todo de pago.
- Interfaz moderna desarrollada en Next.js con TypeScript y Shadcn/ui.

### Infraestructura
- Proyecto dockerizado: backend, frontend y base de datos.
- Scripts reproducibles para carga de datos y entorno local.
- Preparado para integraci√≥n continua y despliegue automatizado.

---

## ‚úÖ TODO

### **Setup Inicial**
- [X] Estructura de proyecto (backend/frontend/data)
- [X] Setup de Django y DRF
- [X] Configurar Docker-compose
- [X] Crear modelos base

### **ETL**
- [X] Crear script para limpiar y validar data
- [X] Crear script para cargar data
- [X] Optimizar carga con `bulk_create`
- [X] Crear task para ejecutar el proceso ETL de forma programada
- [X] Hacer pruebas de `clean_data` y `load_data`
- [X] A√±adir management command para correr ETL manualmente
- [?] Simular actualizaciones peri√≥dicas con Celery

### **API**
- [X] Crear endpoint `/api/customers/insights/` para ver Customer Insights
- [X] Implementar filtros din√°micos
- [X] A√±adir anotaciones y agregaciones a los insights
- [X] Hacer pruebas del endpoint con distintos filtros y combinaciones
- [X] Configurar GitHub Actions para ejecutar pruebas del backend con Docker
- [X] Cachear resultados e invalidarlos cuando se cargue nueva data
- [X] Generar documentaci√≥n del API

### **Frontend**
- [X] Configuracion inicial del proyecto
- [X] Configurar rutas y estructura base del proyecto
- [X] Instalar y configurar Shadcn/UI y Recharts
- [ ] Configurar react-query y filtros

### **Deployment**
- [ ] ...

---

## Decisiones T√©cnicas

### üóÑÔ∏è Modelado de la Base de Datos

Se normaliz√≥ la informaci√≥n en cuatro tablas principales: Clientes, Productos, Variantes de Productos y √ìrdenes. Se definieron √≠ndices en los campos que se anticipan como los m√°s utilizados para filtrar la informaci√≥n en el panel de control. Se establecieron valores predeterminados (`defaults`) para campos donde la ausencia de datos no afectar√≠a significativamente el an√°lisis estad√≠stico. Tambi√©n se identificaron los campos obligatorios, cuya ausencia resultar√≠a en la exclusi√≥n del registro para mantener la integridad de los datos esenciales.

### üßº Limpieza y Validaci√≥n de Datos (ETL)

Se dise√±√≥ una funci√≥n de limpieza (`clean_data`) que valida la estructura del archivo CSV, descarta filas incompletas o duplicadas y aplica reglas de normalizaci√≥n para asegurar la coherencia de los datos antes de cargarlos en la base de datos. Se descartaron registros sin campos cr√≠ticos como ID del cliente, producto o monto de compra, y se eliminaron duplicados basados en `customer id`, que se asume como identificador √∫nico.

Se definieron valores por defecto basados en los modelos (`choices`) para los campos faltantes, como `"unknown"` para valores categ√≥ricos, `False` para booleanos, y mediana o moda para datos num√©ricos. Adem√°s, se estandariz√≥ todo el texto a min√∫sculas y sin espacios extra, y se garantiz√≥ que cada producto tuviera una √∫nica categor√≠a consistente, basada en la moda por nombre de producto.

### üì• Carga de Datos en Base de Datos

Se implement√≥ la funci√≥n `load_data` para poblar las tablas del sistema utilizando el ORM de Django de forma eficiente y segura. Se emple√≥ `bulk_create` para minimizar la cantidad de queries al insertar nuevos registros de clientes, productos, variantes y √≥rdenes.

Para evitar errores por duplicados en clientes, se consultaron previamente los `customer_id` existentes en la base de datos y se excluyeron del conjunto a insertar. En lugar de utilizar `get_or_create` dentro de bucles ‚Äîlo cual implicar√≠a una gran cantidad de queries‚Äî, se construyeron diccionarios de b√∫squeda (`product_lookup`, `variant_lookup`, etc.) que mapean combinaciones clave como `(name, category, season)` para productos y `(product, size, color)` para variantes, permitiendo resolver referencias sin acceso repetido a la base de datos.

Una vez resueltas todas las relaciones con `Customer` y `ProductVariant`, se procedi√≥ a insertar las √≥rdenes tambi√©n mediante `bulk_create`. Este enfoque asegura una carga de datos robusta, eficiente y libre de errores de integridad, optimizada para grandes vol√∫menes de informaci√≥n.

### üìä Dise√±o del API

El endpoint `/api/customers/insights/` fue dise√±ado para proporcionar estad√≠sticas clave sobre los clientes y sus patrones de compra a trav√©s de una √∫nica consulta altamente personalizable. Algunas decisiones clave:

- **Queryset principal:** Se utiliza `Order.objects.select_related(...)` como base, ya que los filtros como categor√≠a de producto o frecuencia de compra dependen tanto de los datos del cliente como del producto. A partir de las √≥rdenes se construye el conjunto de clientes √∫nicos.

- **Filtrado:** Se implement√≥ `DjangoFilterBackend` con una clase de filtro personalizada `CustomerInsightsFilter`, lo que permite aplicar filtros como `gender`, `age range`, `subscription`, `purchase frequency`, y `product category` directamente desde los query params del cliente.

- **Agregaciones:** Las m√©tricas como `total_sales`, `average_order_value`, `avg_review_rating`, etc., se calculan usando agregaciones (`Avg`, `Sum`, `Count`) directamente sobre el queryset filtrado.

- **Distribuciones:** Para visualizaciones front-end como gr√°ficos de barras o stacked charts, se generaron distribuciones pivotadas por g√©nero (ej. `customer_distribution_by_age`, `total_sales_by_category_gender`, etc.) usando una utilidad (`pivot_grouped_by_gender`) que transforma los resultados en un formato amigable para el frontend.

- **Rendimiento:** Se implement√≥ caching con invalidaci√≥n autom√°tica cuando se corre nuevamente el ETL. La clave del cache se construye a partir de los filtros aplicados.

- **Documentaci√≥n OpenAPI:** Se us√≥ `drf-spectacular` para documentar par√°metros de filtro, estructuras de respuesta y tipos de datos, asegurando que el frontend tenga una referencia clara de c√≥mo consumir el endpoint.

---

## Futuras mejoras
- Agrupar colores de productos por sombras/color principal
- Filtros cargados dinamicamente desde el API
- Implementar Factory Boy para generar datos de prueba de forma m√°s mantenible
- Usar Redis como cach√© para mejor escalabilidad
- Implementar autenticaci√≥n y autorizaci√≥n para el API
- A√±adir pipeline de CI/CD completo (staging, production)

---
