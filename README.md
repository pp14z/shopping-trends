# Shopping Trends - ETL, API REST y Dashboard de An√°lisis

## üìå Descripci√≥n general

Soluci√≥n end-to-end para el an√°lisis de tendencias de compra. El sistema extrae datos de transacciones (3,900+ registros), los transforma con Python/Pandas, los almacena en PostgreSQL y los expone a trav√©s de una API REST para su visualizaci√≥n en un dashboard interactivo.

**Tecnolog√≠as**:
- **ETL**: Pandas, Celery
- **Backend**: Django REST Framework (DRF), PostgreSQL
- **Frontend**: Next.js, TypeScript, Shadcn/ui
- **Infraestructura**: Docker-compose

---

## üöÄ Funcionalidades Clave

### ETL
- Ingesta de datos simulando una carga desde S3 (archivo CSV local).
- Limpieza y transformaci√≥n de datos con Pandas.
- Normalizaci√≥n del dataset en un modelo relacional (clientes, productos, transacciones).
- Carga optimizada a PostgreSQL utilizando inserciones masivas (`bulk_create`).
- Estructura preparada para ejecuci√≥n peri√≥dica con Celery (actualizaciones autom√°ticas).

### API REST
- Endpoints organizados por recurso: clientes, productos, ventas.
- Soporte para filtros y b√∫squedas por par√°metros clave.
- Documentaci√≥n generada autom√°ticamente con Swagger / OpenAPI.
- Validaci√≥n de datos y manejo de errores consistente.

### Dashboard Interactivo
- Visualizaci√≥n de KPIs: ventas totales, productos m√°s vendidos, ingresos promedio por categor√≠a.
- Gr√°ficos din√°micos integrados con Chart.js o Recharts.
- Filtros interactivos por categor√≠a, temporada y m√©todo de pago.
- Interfaz moderna desarrollada en Next.js con TypeScript y Shadcn/ui.

### Infraestructura
- Proyecto dockerizado: backend, frontend y base de datos.
- Scripts reproducibles para carga de datos y entorno local.
- Preparado para integraci√≥n continua y despliegue automatizado.

---

## ‚úÖ TODO

### **Setup Inicial**
- [X] Estructura de proyecto (backend/frontend/data)
- [X] Setup de Django y DRF
- [X] Configurar Docker-compose
- [X] Crear modelos base

### **ETL**
- [ ] Crear script de carga inicial con Pandas
- [ ] Optimizar con `bulk_create`
- [ ] Limpiar datos (nulos, formatos)
- [ ] Simular actualizaciones peri√≥dicas con Celery

### **API**
- [ ] ...

### **Frontend**
- [ ] ...

### **Deployment**
- [ ] ...

---

## Decisiones T√©cnicas

### üóÑÔ∏è Modelado de la Base de Datos

Se normaliz√≥ la informaci√≥n en cuatro tablas principales: Clientes, Productos, Variantes de Productos y √ìrdenes. Se definieron √≠ndices en los campos que se anticipan como los m√°s utilizados para filtrar la informaci√≥n en el panel de control. Se establecieron valores predeterminados (`defaults`) para campos donde la ausencia de datos no afectar√≠a significativamente el an√°lisis estad√≠stico. Tambi√©n se identificaron los campos obligatorios, cuya ausencia resultar√≠a en la exclusi√≥n del registro para mantener la integridad de los datos esenciales.

### üîç Validaci√≥n y limpieza de datos

Antes de cargar los datos en la base de datos, el archivo CSV pasa por un proceso de validaci√≥n y limpieza dentro de la funci√≥n `clean_data()`.

- Se verifica que el archivo contenga todas las columnas requeridas.
- Se ignoran columnas adicionales que no forman parte del esquema esperado.
- Se valida que los tipos de datos sean consistentes con cada campo.
- Se comprueba que valores cr√≠ticos tengan valores v√°lidos (por ejemplo: `"Yes"`/`"No"` en campos booleanos).

### üß® Filtrado de filas inv√°lidas
Las filas que contienen datos faltantes en alguno de los siguientes campos cr√≠ticos se descartan completamente:

- `Customer ID` (identificador de cliente)
- `Item Purchased` (producto comprado)
- `Purchase Amount (USD)` (monto de la compra)

Estas columnas son necesarias para mantener la integridad de las relaciones y para el c√°lculo correcto de m√©tricas.

--

## Futuras mejoras
- Agrupar colores de productos por sombras/color principal?
- 

--


